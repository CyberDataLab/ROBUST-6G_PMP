#Just in case of debug
#<system>
  #log_level debug
#</system>

<source>
  @type systemd
  @id source_systemd
  path /var/log/journal
  <storage>
    @type local
    persistent true
    path /fluentd/log/fluentd-journal-pos.json
  </storage>
  <entry>
    fields_strip_underscores true
    fields_lowercase true
  </entry>
  tag systemd
</source>

<source>
  @type tail
  @id source_syslog
  path /var/log/syslog
  pos_file /fluentd/log/fluentd-syslog.pos
  tag syslog
  format syslog
</source>

# Expose metrics in Prometheus format via HTTP to be scraped by Prometheus itself. There is NO need for a “match” because Prometheus itself is in charge of retrieving them.
<source>
  @type prometheus
  @id source_prometheus
  bind 0.0.0.0
  port 24231
</source>

# Fluentd Internal Metrics
<source>
  @type monitor_agent
  @id source_in_monitor_agent
  tag internal_metrics_fluentd
  bind 0.0.0.0
  port 24220
  emit_interval 20
</source>

<source>
  @type exec
  @id source_exec_metric_script
  command /fluentd/scripts/health_metrics.py
  tag system.metrics
  run_interval 5
   <parse>
    @type json
  </parse>
</source>


<filter system.metrics>
  @type typecast
  @id filter_parse_string_to_float_host_metrics
  types cpu_usage:float,memory_mb:float
</filter>

<filter internal_metrics_fluentd>
  @type typecast
  @id filter_parse_string_to_float_fluentd_metrics
  types buffer_queue_length:float,buffer_total_queued_size:float,retry_count:float
</filter>

# Filter for systemd data formatting
<filter systemd>
  @type record_transformer
  enable_ruby true
  renew_record true
  keep_keys priority,syslog_facility,syslog_identifier,job_type,job_result,message,pid,uid,gid,comm,exe,cmdline,unit
  <record>
    # Rename data. If a key does not exist, it remains empty or null, and does not produce an error.
    machine_id      "#{ENV['MACHINE_ID']}"
    priority        ${record["priority"]}
    facility        ${record["syslog_facility"]}
    identifier      ${record["syslog_identifier"]}
    job_type        ${record["job_type"]}
    job_result      ${record["job_result"]}
    message         ${record["message"]}
    pid             ${record["pid"]}
    uid             ${record["uid"]}
    gid             ${record["gid"]}
    comm            ${record["comm"]}
    exe             ${record["exe"]}
    cmdline         ${record["cmdline"]}
    unit            ${record["unit"]}
  </record>
</filter>

# Filter for sysslog data formatting
<filter syslog>
  @type record_transformer
  enable_ruby true
  <record>
    machine_id "#{ENV['MACHINE_ID']}"
  </record>
</filter>



# Mapping to Prometheus. 
<match system.metrics>
  @type prometheus
  @id match_host_system_metrics_to_prometheus

  <metric>
    name system_cpu_usage
    type gauge
    desc is the CPU usage percentage
    key cpu_usage
  </metric>

  <metric>
    name system_memory_available_mb
    type gauge
    desc is the memory available in MB
    key memory_mb
  </metric>
</match>

# Fluentd internal metrics match
<match internal_metrics_fluentd>
  @type prometheus
  @id match_metric_agent_to_prometheus

  <metric>
    name fluentd_output_status_buffer_queue_length
    type gauge
    desc is the length of the buffer queue for outputs
    key buffer_queue_length
  </metric>

  <metric>
    name fluentd_output_status_retry_count
    type counter
    desc is the number of retries
    key retry_count
  </metric>

  <metric>
    name fluentd_buffer_total_queued_size
    type gauge
    desc is the total queue size in bytes
    key buffer_total_queued_size
  </metric>
</match>


#Output file management
#FIXME take into account “logrotate” in order not to accumulate too many logs.
<match systemd>
  @type file
  path /fluentd/log/out/systemd_output.log
  append true
  <buffer>
    flush_mode interval
    flush_interval 20s
  </buffer>
</match>

<match syslog>
  @type file
  @id match_syslog_to_stdout
  path /fluentd/log/out/syslog_output.log
  append  true
  <buffer>
    #flush_mode immediate -> only with powerful machines
    flush_mode interval
    flush_interval 20s
  </buffer>
</match>

