#Just in case of debug
#<system>
  #log_level debug
#</system>

<source>
  @type systemd
  @id source_systemd
  path /var/log/journal
  <storage>
    @type local
    persistent true
    path /fluentd/log/fluentd-journal-pos.json
  </storage>
  <entry>
    fields_strip_underscores true #If true, strip leading underscores from all non-mapped fields. Defaults to false.
    fields_lowercase true #If true, lowercase all non-mapped fields. Defaults to false.
  </entry>
  tag systemd
</source>

<source>
  @type tail
  @id source_syslog
  path /var/log/syslog
  pos_file /fluentd/log/fluentd-syslog.pos
  tag syslog
  format syslog
</source>

#Exponer métricas en formato Prometheus mediante HTTP para que las scrapee el propio Prometheus. NO hace falta un "match" porque
#es el propio Prometheus el que se encarga de venir a buscarlas.
<source>
  @type prometheus
  @id source_prometheus
  # La dirección y puerto donde se expondrán las métricas.
  # Por defecto las métricas estarán disponibles en http://localhost:24231/metrics y se pueden ver si se mapea el puerto en el contenedor
  # aunque para el funcionamiento normal no es necesario.
  bind 0.0.0.0
  port 24231
</source>

#Metricas internas de Fluentd
<source>
  @type monitor_agent
  @id source_in_monitor_agent
  tag internal_metrics_fluentd
  bind 0.0.0.0
  port 24220
  emit_interval 20
</source>

<source>
  @type exec
  @id source_exec_metric_script
  command /fluentd/scripts/health_metrics.py
  tag system.metrics
  run_interval 5
  #Parece que la versión moderna de exec ya no usa "format", si no "parse"
  <parse>
    @type json
  </parse>
</source>


# Como los datos vienen en formato string, hay que hacer un parseo a float, si no, prometheus no lo entiende.
<filter system.metrics>
  @type typecast
  @id filter_parse_string_to_float_host_metrics
  types cpu_usage:float,memory_mb:float
</filter>

<filter internal_metrics_fluentd>
  @type typecast
  @id filter_parse_string_to_float_fluentd_metrics
  types buffer_queue_length:float,buffer_total_queued_size:float,retry_count:float
</filter>

#Filtro para systemd para hacer lo mismo que el syslog y escribirlo en un fichero
<filter systemd>
  @type record_transformer
  enable_ruby true
  renew_record true
  keep_keys priority,syslog_facility,syslog_identifier,job_type,job_result,message,pid,uid,gid,comm,exe,cmdline,unit
  <record>
    # Aquí renombramos o copiamos. Si una clave no existe en el evento actual, este placeholder queda vacío o nulo, y no produce error.
    machine_id      "#{ENV['MACHINE_ID']}"
    priority        ${record["priority"]}
    facility        ${record["syslog_facility"]}
    identifier      ${record["syslog_identifier"]}
    job_type        ${record["job_type"]}
    job_result      ${record["job_result"]}
    message         ${record["message"]}
    pid             ${record["pid"]}
    uid             ${record["uid"]}
    gid             ${record["gid"]}
    comm            ${record["comm"]}
    exe             ${record["exe"]}
    cmdline         ${record["cmdline"]}
    unit            ${record["unit"]}
  </record>
</filter>

#Filtro para syslog para hacer lo mismo que el systemd y escribirlo en un fichero
<filter syslog>
  @type record_transformer
  enable_ruby true
  <record>
    machine_id "#{ENV['MACHINE_ID']}"
  </record>
</filter>



# Mapear a Prometheus. 
# OJO: label_keys y labels_from_record van a nivel de <match>, no dentro de <metric>.
<match system.metrics>
  @type prometheus
  @id match_host_system_metrics_to_prometheus

  <metric>
    name system_cpu_usage
    type gauge
    desc is the CPU usage percentage
    key cpu_usage
  </metric>

  <metric>
    name system_memory_available_mb
    type gauge
    desc is the memory available in MB
    key memory_mb
  </metric>
</match>

# Metricas internas de Fluentd
<match internal_metrics_fluentd>
  @type prometheus
  @id match_metric_agent_to_prometheus

  <metric>
    name fluentd_output_status_buffer_queue_length
    type gauge
    desc is the length of the buffer queue for outputs
    key buffer_queue_length
  </metric>

  <metric>
    name fluentd_output_status_retry_count
    type counter
    desc is the number of retries
    key retry_count
  </metric>

  <metric>
    name fluentd_buffer_total_queued_size
    type gauge
    desc is the total queue size in bytes
    key buffer_total_queued_size
  </metric>
</match>


#Los logs se van a guardar en un fichero (uno para systemd y otro para syslog) para que FileBeat pueda leerlos y enviarlos a Kafka. 
#FIXME tener en cuenta "logrotate" para no acumular muchos logs.
<match systemd>
  @type file
  path /fluentd/log/out/systemd_output.log
  append true
  <buffer>
    flush_mode interval
    flush_interval 20s
  </buffer>
</match>

<match syslog>
  @type file
  @id match_syslog_to_stdout
  path /fluentd/log/out/syslog_output.log
  append  true
  <buffer>
    #flush_mode immediate -> only with powerful machines
    flush_mode interval
    flush_interval 20s
  </buffer>
</match>

